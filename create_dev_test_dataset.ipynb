{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6060c419-a112-44b2-8cc9-38971beb51ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "from fastparquet import write\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from utils import read_df, write_df\n",
    "from feature_extraction import extract_features_per_sku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41290256-8712-4f38-a532-f54bd434fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FOLDER = \"./dataset\"\n",
    "#train_processed_data = os.path.join(DATASET_FOLDER, 'processed/sku_feature_data.parquet')\n",
    "train_data = os.path.join(DATASET_FOLDER, 'train_data.parquet')\n",
    "item_data = os.path.join(DATASET_FOLDER, 'items_static_metadata_full.jl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e716728-8071-4f23-8b1a-cb5ef01b8654",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = \"./dataset/processed/train_v2\"\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c211d16-3c2c-4a5b-be55-5988d62f57eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_parquet(train_data, engine='fastparquet')\n",
    "\n",
    "#df_train_v1 = pd.read_parquet(train_processed_data, engine='fastparquet')\n",
    "#df_train_v1 = df_train_v1.set_index('sku')\n",
    "\n",
    "df_item = pd.read_json(item_data, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3438da4-6954-497c-a5b8-a06dc9778a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "skus = df_train['sku'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "688e2615-1e1f-4374-bb7d-38d4a286a53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sku to index on train data\n",
    "index_to_sku = df_train[df_train['sku'].diff() != 0]['sku']\n",
    "shifted_index = np.append(index_to_sku.index.values[1:].copy(), [len(df_train)])\n",
    "index_range = list(zip(index_to_sku.index.values, shifted_index))\n",
    "sku_to_index_range = pd.Series(index_range, index=index_to_sku)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14ebc0b0-0165-4a14-a874-4ecd9b11d4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=4, random_state=None, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef207228-6148-4ac5-81cf-e6100e4adc9b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 495687 165229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-0bb2e2ad70e9>\", line 51, in <module>\n",
      "    write_df(df_kfold_train, os.path.join(data_target_folder, 'train_data.parquet'))\n",
      "  File \"/home/edugarcia/kaggle/ml2021/utils.py\", line 34, in write_df\n",
      "    write(path, df)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/fastparquet/writer.py\", line 956, in write\n",
      "    compression, open_with, has_nulls, append)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/fastparquet/writer.py\", line 790, in write_simple\n",
      "    compression=compression)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/fastparquet/writer.py\", line 656, in make_row_group\n",
      "    compression=comp)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/fastparquet/writer.py\", line 534, in write_column\n",
      "    repetition_data, definition_data, encode[encoding](data, selement), 8 * b'\\x00'\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/fastparquet/writer.py\", line 348, in encode_plain\n",
      "    return pack_byte_array(list(out))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-0bb2e2ad70e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m#Write data to folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mwrite_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_kfold_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_target_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train_data.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mwrite_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_kfold_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_target_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test_fromtrain_data.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/kaggle/ml2021/utils.py\u001b[0m in \u001b[0;36mwrite_df\u001b[0;34m(df, path, index, header)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.parquet'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/fastparquet/writer.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(filename, data, row_group_offsets, compression, file_scheme, open_with, mkdirs, has_nulls, write_index, partition_on, fixed_text, append, object_encoding, times, custom_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m         write_simple(filename, data, fmd, row_group_offsets,\n\u001b[0;32m--> 956\u001b[0;31m                      compression, open_with, has_nulls, append)\n\u001b[0m\u001b[1;32m    957\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mfile_scheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'hive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'drill'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/fastparquet/writer.py\u001b[0m in \u001b[0;36mwrite_simple\u001b[0;34m(fn, data, fmd, row_group_offsets, compression, open_with, has_nulls, append)\u001b[0m\n\u001b[1;32m    789\u001b[0m             rg = make_row_group(f, data[start:end], fmd.schema,\n\u001b[0;32m--> 790\u001b[0;31m                                 compression=compression)\n\u001b[0m\u001b[1;32m    791\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/fastparquet/writer.py\u001b[0m in \u001b[0;36mmake_row_group\u001b[0;34m(f, data, schema, compression)\u001b[0m\n\u001b[1;32m    655\u001b[0m             chunk = write_column(f, data[column.name], column,\n\u001b[0;32m--> 656\u001b[0;31m                                  compression=comp)\n\u001b[0m\u001b[1;32m    657\u001b[0m             \u001b[0mrg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/fastparquet/writer.py\u001b[0m in \u001b[0;36mwrite_column\u001b[0;34m(f, data, selement, compression, datapage_version)\u001b[0m\n\u001b[1;32m    533\u001b[0m         bdata = b\"\".join([\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mrepetition_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefinition_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mselement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34mb'\\x00'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m         ])\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/fastparquet/writer.py\u001b[0m in \u001b[0;36mencode_plain\u001b[0;34m(data, se)\u001b[0m\n\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mparquet_thrift\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBYTE_ARRAY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpack_byte_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "for kfold, (train_index, test_index) in enumerate(kf.split(skus)):\n",
    "    print(kfold, len(train_index), len(test_index))\n",
    "    \n",
    "    #Create folder structure\n",
    "    data_target_folder = os.path.join(target_folder, str(kfold))\n",
    "    if not os.path.exists(data_target_folder):\n",
    "        os.makedirs(data_target_folder)\n",
    "    \n",
    "    #Pick last 30 datapoints from train\n",
    "    def pick_last_30(index_range):\n",
    "        x1, x2 = index_range\n",
    "        if x2-x1 <= 30:\n",
    "            return np.array([np.nan])\n",
    "        else:\n",
    "            return np.arange(x2-30, x2)\n",
    "\n",
    "    test_df_index = np.concatenate(sku_to_index_range[test_index].apply(pick_last_30).values)\n",
    "    test_df_index = test_df_index[~np.isnan(test_df_index)].astype('int64')\n",
    "    df_kfold_test = df_train.loc[test_df_index]\n",
    "    \n",
    "    #Remove sku's with total sold_quantity == 0 from test set\n",
    "    test_zero_solded_sku = df_kfold_test.groupby('sku')['sold_quantity'].sum() == 0\n",
    "    invalid_sku = test_zero_solded_sku[test_zero_solded_sku].index.values\n",
    "    df_kfold_test = df_kfold_test[~df_kfold_test['sku'].isin(invalid_sku)]\n",
    "    \n",
    "    #Rebuild train data with rows not in test data\n",
    "    df_kfold_train = df_train.loc[~df_train.index.isin(df_kfold_test.index)].copy().reset_index(drop=True)\n",
    "    df_kfold_test = df_kfold_test.copy().reset_index(drop=True)\n",
    "    \n",
    "    #Build test data with random target_stock\n",
    "    test_sold_quantity_agg = df_kfold_test.groupby('sku')['sold_quantity'].agg(list).apply(np.array)\n",
    "    test_sold_quantity_possibilites = test_sold_quantity_agg.apply(np.cumsum).apply(lambda x: np.unique(x, return_index=True))\n",
    "    \n",
    "    def random_choose_target_stock(x):\n",
    "        target_stocks, target_dates = x\n",
    "        #ignore target_stock == 0\n",
    "        if target_stocks[0] == 0:\n",
    "            target_stocks = target_stocks[1:]\n",
    "            target_dates = target_dates[1:]\n",
    "        randint = np.random.randint(0, target_stocks.shape[0])\n",
    "        target_date = target_dates[randint]\n",
    "        target_stock = target_stocks[randint]\n",
    "        return target_stock, target_date_0\n",
    "\n",
    "    test_data = test_sold_quantity_possibilites.apply(random_choose_target_stock)\n",
    "    test_data = pd.DataFrame([[sku, stock, date] for sku, (stock, date) in zip(test_data.index.values, test_data.values)], columns=['sku','target_stock', 'target_date_0'])\n",
    "    \n",
    "    ground_truth = np.eye(30)[test_data['target_date_0'].values]\n",
    "    \n",
    "    #Write data to folder\n",
    "    write_df(df_kfold_train, os.path.join(data_target_folder, 'train_data.parquet'))\n",
    "    write_df(df_kfold_test, os.path.join(data_target_folder, 'test_fromtrain_data.parquet'))\n",
    "    write_df(test_data[['sku', 'target_stock']], os.path.join(data_target_folder, 'test_data.csv'))\n",
    "    write_df(pd.DataFrame(ground_truth), os.path.join(data_target_folder, 'test_ground_truth.csv'), header=False)\n",
    "    np.save(os.path.join(data_target_folder, 'test_ground_truth.npy'), ground_truth)\n",
    "    \n",
    "    with open(os.path.join(data_target_folder, 'test_sku.txt'), 'w') as f:\n",
    "        for sku in test_data['sku']:\n",
    "            f.write(str(sku)+'\\n')\n",
    "            \n",
    "    #Feature extraction train data\n",
    "    df_kfold_train_processed = extract_features_per_sku(df_kfold_train, df_item)\n",
    "    \n",
    "    write_df(df_kfold_train_processed, os.path.join(data_target_folder, 'train_sku_feature_data.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "124e6f06-5368-4b30-91a3-2304d9ce85de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554ce49ae9ae4535a38ea459a0efd126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/660916 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_kfold_train_processed = extract_features_per_sku(df_kfold_train, df_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d3da9d0-5b00-4c4e-83f4-e3e86b1af26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29    4077120\n",
       "26      18180\n",
       "28      14670\n",
       "27      12690\n",
       "19      12510\n",
       "25      12210\n",
       "18      11610\n",
       "20      11250\n",
       "13      10230\n",
       "6       10170\n",
       "22      10050\n",
       "21       9780\n",
       "5        9720\n",
       "12       9600\n",
       "7        9270\n",
       "8        9270\n",
       "11       8310\n",
       "15       8310\n",
       "14       7920\n",
       "4        7830\n",
       "1        7770\n",
       "24       6780\n",
       "17       4440\n",
       "23       4020\n",
       "10       3330\n",
       "3        3120\n",
       "9        2550\n",
       "16       2490\n",
       "2        2400\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kfold_train_processed.set_index('sku').loc[df_kfold_test['sku']]['count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7cd392bc-049e-48a2-b5e8-394255aabdc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29    135904\n",
       "26       606\n",
       "28       489\n",
       "27       423\n",
       "19       417\n",
       "25       407\n",
       "18       387\n",
       "20       375\n",
       "13       341\n",
       "6        339\n",
       "22       335\n",
       "21       326\n",
       "5        324\n",
       "12       320\n",
       "7        309\n",
       "8        309\n",
       "11       277\n",
       "15       277\n",
       "14       264\n",
       "4        261\n",
       "1        259\n",
       "24       226\n",
       "17       148\n",
       "23       134\n",
       "10       111\n",
       "3        104\n",
       "9         85\n",
       "16        83\n",
       "2         80\n",
       "Name: sku, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kfold_train[df_kfold_train['sku'].isin(df_kfold_test['sku'])]['sku'].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd0bd900-af37-41e8-b051-34a47e0968fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>date</th>\n",
       "      <th>sold_quantity</th>\n",
       "      <th>current_price</th>\n",
       "      <th>currency</th>\n",
       "      <th>listing_type</th>\n",
       "      <th>shipping_logistic_type</th>\n",
       "      <th>shipping_payment</th>\n",
       "      <th>minutes_active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-03-02</td>\n",
       "      <td>0</td>\n",
       "      <td>135.90</td>\n",
       "      <td>REA</td>\n",
       "      <td>premium</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-03-03</td>\n",
       "      <td>0</td>\n",
       "      <td>135.90</td>\n",
       "      <td>REA</td>\n",
       "      <td>premium</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-03-04</td>\n",
       "      <td>0</td>\n",
       "      <td>135.90</td>\n",
       "      <td>REA</td>\n",
       "      <td>premium</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-03-05</td>\n",
       "      <td>1</td>\n",
       "      <td>135.90</td>\n",
       "      <td>REA</td>\n",
       "      <td>premium</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-03-06</td>\n",
       "      <td>0</td>\n",
       "      <td>135.90</td>\n",
       "      <td>REA</td>\n",
       "      <td>premium</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>free_shipping</td>\n",
       "      <td>1440.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317595</th>\n",
       "      <td>660915</td>\n",
       "      <td>2021-03-27</td>\n",
       "      <td>0</td>\n",
       "      <td>79.99</td>\n",
       "      <td>MEX</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>paid_shipping</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317596</th>\n",
       "      <td>660915</td>\n",
       "      <td>2021-03-28</td>\n",
       "      <td>0</td>\n",
       "      <td>79.99</td>\n",
       "      <td>MEX</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>paid_shipping</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317597</th>\n",
       "      <td>660915</td>\n",
       "      <td>2021-03-29</td>\n",
       "      <td>0</td>\n",
       "      <td>79.99</td>\n",
       "      <td>MEX</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>paid_shipping</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317598</th>\n",
       "      <td>660915</td>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>0</td>\n",
       "      <td>99.99</td>\n",
       "      <td>MEX</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>paid_shipping</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4317599</th>\n",
       "      <td>660915</td>\n",
       "      <td>2021-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>99.99</td>\n",
       "      <td>MEX</td>\n",
       "      <td>classic</td>\n",
       "      <td>fulfillment</td>\n",
       "      <td>paid_shipping</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4317600 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            sku        date  sold_quantity  current_price currency  \\\n",
       "0             1  2021-03-02              0         135.90      REA   \n",
       "1             1  2021-03-03              0         135.90      REA   \n",
       "2             1  2021-03-04              0         135.90      REA   \n",
       "3             1  2021-03-05              1         135.90      REA   \n",
       "4             1  2021-03-06              0         135.90      REA   \n",
       "...         ...         ...            ...            ...      ...   \n",
       "4317595  660915  2021-03-27              0          79.99      MEX   \n",
       "4317596  660915  2021-03-28              0          79.99      MEX   \n",
       "4317597  660915  2021-03-29              0          79.99      MEX   \n",
       "4317598  660915  2021-03-30              0          99.99      MEX   \n",
       "4317599  660915  2021-03-31              0          99.99      MEX   \n",
       "\n",
       "        listing_type shipping_logistic_type shipping_payment  minutes_active  \n",
       "0            premium            fulfillment    free_shipping          1440.0  \n",
       "1            premium            fulfillment    free_shipping          1440.0  \n",
       "2            premium            fulfillment    free_shipping          1440.0  \n",
       "3            premium            fulfillment    free_shipping          1440.0  \n",
       "4            premium            fulfillment    free_shipping          1440.0  \n",
       "...              ...                    ...              ...             ...  \n",
       "4317595      classic            fulfillment    paid_shipping             0.0  \n",
       "4317596      classic            fulfillment    paid_shipping             0.0  \n",
       "4317597      classic            fulfillment    paid_shipping             0.0  \n",
       "4317598      classic            fulfillment    paid_shipping             0.0  \n",
       "4317599      classic            fulfillment    paid_shipping             0.0  \n",
       "\n",
       "[4317600 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kfold_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
