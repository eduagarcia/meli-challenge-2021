{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44f23597-5825-42bb-a659-276f75c81feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 50 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 50 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "INFO: Pandarallel will run on 50 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from models import models\n",
    "from utils import read_df, read_numpy, write_df\n",
    "import logging\n",
    "\n",
    "from evaluate import rps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "567c0430-f42f-4172-aa1b-95b9844b4c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 50 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "#Model imports\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from multiprocessing import Pool\n",
    "from iteround import saferound\n",
    "import scipy.stats as st\n",
    "import tweedie\n",
    "from category_encoders import OrdinalEncoder\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(nb_workers=50)\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from model import Model\n",
    "from utils import read_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf4f4aee-d9b6-41e0-aa6b-0f52fb5c7cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = './dataset/processed/train_v1'\n",
    "TEST_DATA_FILENAME = 'test_data.csv'\n",
    "GROUND_TRUTH_FILENAME = 'test_ground_truth.npy'\n",
    "TRAIN_DATA_FILENAME = 'train_data.parquet'\n",
    "TRAIN_DATA_PROCESSED_FILENAME = 'train_data_features.parquet'\n",
    "ITEM_DATA_FILEPATH = './dataset/items_static_metadata_full.jl'\n",
    "\n",
    "TRAIN_DATA_X_FILENAME = 'train_data_x.parquet'\n",
    "TRAIN_DATA_Y_FILENAME = 'train_data_y.parquet'\n",
    "TRAIN_DATA_X_PROCESSED_FILENAME = 'train_data_x_features.parquet'\n",
    "TRAIN_DATA_Y_PROCESSED_FILENAME = 'train_data_y_features.parquet'\n",
    "\n",
    "TEST_FROMTRAIN_DATA_LAST29_FILENAME = 'test_fromtrain_data_last29.parquet'\n",
    "TEST_FROMTRAIN_DATA_LAST29_PROCESSED_FILENAME = 'test_fromtrain_data_last29_features.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0096aa19-d5d3-44cf-a864-8bd155caa98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dateset_indexes = [0]\n",
    "model_name = 'simple_first_30_days_fixed_spike'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73c79cd0-b59f-4382-823b-22a1f40e1263",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_index = dateset_indexes[0]\n",
    "dataset_current_path = os.path.join(DATASET_PATH, str(dataset_index))\n",
    "\n",
    "test_data_filepath = os.path.join(dataset_current_path, TEST_DATA_FILENAME)\n",
    "ground_truth_filepath = os.path.join(dataset_current_path, GROUND_TRUTH_FILENAME)\n",
    "train_data_filepath = os.path.join(dataset_current_path, TRAIN_DATA_FILENAME)\n",
    "train_data_processed_filepath = os.path.join(dataset_current_path, TRAIN_DATA_PROCESSED_FILENAME)\n",
    "\n",
    "train_data_x_filepath = os.path.join(dataset_current_path, TRAIN_DATA_X_FILENAME)\n",
    "train_data_y_filepath = os.path.join(dataset_current_path, TRAIN_DATA_Y_FILENAME)\n",
    "train_data_x_processed_filepath = os.path.join(dataset_current_path, TRAIN_DATA_X_PROCESSED_FILENAME)\n",
    "train_data_y_processed_filepath = os.path.join(dataset_current_path, TRAIN_DATA_Y_PROCESSED_FILENAME)\n",
    "\n",
    "test_fromtrain_data_last29_filepath = os.path.join(dataset_current_path, TEST_FROMTRAIN_DATA_LAST29_FILENAME)\n",
    "test_fromtrain_data_last29_processed_filepath = os.path.join(dataset_current_path, TEST_FROMTRAIN_DATA_LAST29_PROCESSED_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3b6b21-3f10-4ead-81a1-5bdf1d9c91f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = models['xgboost_v1']('./dataset')\n",
    "#model.prepare_data()\n",
    "#model.train()\n",
    "#model.predict('./dataset/test_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66396109-4efe-4427-9ec2-9fafa2af54cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-1d52857e075c>\", line 2, in <module>\n",
      "    df_item = read_df(ITEM_DATA_FILEPATH)\n",
      "  File \"/home/edugarcia/kaggle/ml2021/utils.py\", line 22, in read_df\n",
      "    return pd.read_json(data, lines=True)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/util/_decorators.py\", line 199, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/util/_decorators.py\", line 296, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 618, in read_json\n",
      "    result = json_reader.read()\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 753, in read\n",
      "    obj = self._get_object_parser(self._combine_lines(data))\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 777, in _get_object_parser\n",
      "    obj = FrameParser(json, **kwargs).parse()\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 886, in parse\n",
      "    self._parse_no_numpy()\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/io/json/_json.py\", line 1119, in _parse_no_numpy\n",
      "    loads(json, precise_float=self.precise_float), dtype=None\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/core/frame.py\", line 521, in __init__\n",
      "    mgr = arrays_to_mgr(arrays, columns, index, columns, dtype=dtype)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/core/internals/construction.py\", line 83, in arrays_to_mgr\n",
      "    arrays = _homogenize(arrays, index, dtype)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/core/internals/construction.py\", line 352, in _homogenize\n",
      "    val, index, dtype=dtype, copy=False, raise_cast_failure=False\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/core/construction.py\", line 513, in sanitize_array\n",
      "    inferred = lib.infer_dtype(subarr, skipna=False)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1d52857e075c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_filepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_item\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mITEM_DATA_FILEPATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/kaggle/ml2021/utils.py\u001b[0m in \u001b[0;36mread_df\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.jl'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'.jsonl'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'invalid data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression, nrows)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshould_close\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    885\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 886\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1119\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m    351\u001b[0m             val = sanitize_array(\n\u001b[0;32m--> 352\u001b[0;31m                 \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_object_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0minferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minferred\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"interval\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"period\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2043\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0;32m-> 2047\u001b[0;31m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[1;32m   2048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2049\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[0;32m-> 1436\u001b[0;31m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[0;32m-> 1336\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m             )\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Minimal'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0;32m-> 1193\u001b[0;31m                                                                tb_offset)\n\u001b[0m\u001b[1;32m   1194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColors\u001b[0m  \u001b[0;31m# just a shorthand + quicker name lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "df_train = read_df(train_data_filepath)\n",
    "df_item = read_df(ITEM_DATA_FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19110026-8ba0-481d-aada-b23beceada42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = read_df(test_data_filepath)\n",
    "ground_truth = read_numpy(ground_truth_filepath)\n",
    "\n",
    "df_train_processed = read_df(train_data_processed_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2ff6e8-c943-4e94-a6ff-dbe651a59674",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train_x = read_df(train_data_x_filepath)\n",
    "#df_train_x = read_df(train_data_y_filepath)\n",
    "\n",
    "df_test_fromtrain_x_features = read_df(test_fromtrain_data_last29_processed_filepath)\n",
    "df_train_x_features = read_df(train_data_x_processed_filepath)\n",
    "df_train_y_features = read_df(train_data_y_processed_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bcf01d-c7bf-486a-bf1d-5059e75d4195",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_df = df_train_x_features.sample(frac=1, random_state=42).reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a779d07c-d01e-4a86-bcfa-66e80da7a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_df = df_train_y_features.set_index('sku').loc[x_df['sku']].reset_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f136fa32-490f-426e-bb50-18a1412d0dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_features, extract_relevant_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51c5417e-e7b1-46a4-9f74-83688f9a0221",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_column = 'sku'\n",
    "sort_column = 'date'\n",
    "numeric_columns = ['sold_quantity', 'current_price', 'minutes_active']\n",
    "\n",
    "features = [id_column] + [sort_column] + numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a02300e8-0cbf-4cc9-a16a-10d1952a2252",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train[features]\n",
    "df = df.sort_values(['sku', 'date']).reset_index(drop=True)\n",
    "df_first_entry = df[df['sku'].diff() != 0]\n",
    "\n",
    "sku_split = []\n",
    "for i in range(len(df_first_entry)-1):\n",
    "    start_index = df_first_entry.index[i]\n",
    "    end_index = df_first_entry.index[i+1]\n",
    "    sku_split.append(df.iloc[start_index:end_index])\n",
    "sku_split.append(df.iloc[end_index:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd90b8db-628a-4b91-9f8f-21f252ed663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df_train[df_train['sku'] == df_train.iloc[0]['sku']]\n",
    "df_train = df_train['features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f9cf26-f756-4d24-aa0f-217d9894d887",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "# We must import this explicitly, it is not imported by the top-level\n",
    "# multiprocessing module.\n",
    "import multiprocessing.pool\n",
    "import time\n",
    "\n",
    "from random import randint\n",
    "\n",
    "\n",
    "class NoDaemonProcess(multiprocessing.Process):\n",
    "    # make 'daemon' attribute always return False\n",
    "    def _get_daemon(self):\n",
    "        return False\n",
    "    def _set_daemon(self, value):\n",
    "        pass\n",
    "    daemon = property(_get_daemon, _set_daemon)\n",
    "\n",
    "# We sub-class multiprocessing.pool.Pool instead of multiprocessing.Pool\n",
    "# because the latter is only a wrapper function, not a proper class.\n",
    "class MyPool(multiprocessing.pool.Pool):\n",
    "    Process = NoDaemonProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f0aee2-0856-4d2c-9799-60975787f7a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "start_time = time.time()\n",
    "\n",
    "extraction_settings = ComprehensiveFCParameters()\n",
    "\n",
    "def create_features_per_sku(df_sku):\n",
    "    x_features_extracted = extract_features(df_sku, column_id='sku', column_sort='date',\n",
    "                         default_fc_parameters=extraction_settings, n_jobs=0, disable_progressbar=True)\n",
    "    return x_features_extracted\n",
    "\n",
    "sku_data = []\n",
    "with Pool(96) as p:\n",
    "    for data in tqdm(p.imap(create_features_per_sku, sku_split), total=len(sku_split)):\n",
    "        sku_data.append(data)\n",
    "\n",
    "df_sku = pd.DataFrame(sku_data)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578bdf9-ee9e-4fb2-bfce-63a1e036db23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9624f6a7-705e-4747-9652-1da5cf47714e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>minutes_active__variance_larger_than_standard_deviation</th>\n",
       "      <th>minutes_active__has_duplicate_max</th>\n",
       "      <th>minutes_active__has_duplicate_min</th>\n",
       "      <th>minutes_active__has_duplicate</th>\n",
       "      <th>minutes_active__sum_values</th>\n",
       "      <th>minutes_active__abs_energy</th>\n",
       "      <th>minutes_active__mean_abs_change</th>\n",
       "      <th>minutes_active__mean_change</th>\n",
       "      <th>minutes_active__mean_second_derivative_central</th>\n",
       "      <th>minutes_active__median</th>\n",
       "      <th>...</th>\n",
       "      <th>current_price__permutation_entropy__dimension_5__tau_1</th>\n",
       "      <th>current_price__permutation_entropy__dimension_6__tau_1</th>\n",
       "      <th>current_price__permutation_entropy__dimension_7__tau_1</th>\n",
       "      <th>current_price__query_similarity_count__query_None__threshold_0.0</th>\n",
       "      <th>current_price__matrix_profile__feature_\"min\"__threshold_0.98</th>\n",
       "      <th>current_price__matrix_profile__feature_\"max\"__threshold_0.98</th>\n",
       "      <th>current_price__matrix_profile__feature_\"mean\"__threshold_0.98</th>\n",
       "      <th>current_price__matrix_profile__feature_\"median\"__threshold_0.98</th>\n",
       "      <th>current_price__matrix_profile__feature_\"25\"__threshold_0.98</th>\n",
       "      <th>current_price__matrix_profile__feature_\"75\"__threshold_0.98</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>464801</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84960.0</td>\n",
       "      <td>122342400.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965937</td>\n",
       "      <td>1.214718</td>\n",
       "      <td>1.431578</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.102753</td>\n",
       "      <td>6.447728</td>\n",
       "      <td>4.95205</td>\n",
       "      <td>5.078272</td>\n",
       "      <td>4.35793</td>\n",
       "      <td>5.504583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 2361 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        minutes_active__variance_larger_than_standard_deviation  \\\n",
       "464801                                                0.0         \n",
       "\n",
       "        minutes_active__has_duplicate_max  minutes_active__has_duplicate_min  \\\n",
       "464801                                1.0                                1.0   \n",
       "\n",
       "        minutes_active__has_duplicate  minutes_active__sum_values  \\\n",
       "464801                            1.0                     84960.0   \n",
       "\n",
       "        minutes_active__abs_energy  minutes_active__mean_abs_change  \\\n",
       "464801                 122342400.0                              0.0   \n",
       "\n",
       "        minutes_active__mean_change  \\\n",
       "464801                          0.0   \n",
       "\n",
       "        minutes_active__mean_second_derivative_central  \\\n",
       "464801                                             0.0   \n",
       "\n",
       "        minutes_active__median  ...  \\\n",
       "464801                  1440.0  ...   \n",
       "\n",
       "        current_price__permutation_entropy__dimension_5__tau_1  \\\n",
       "464801                                           0.965937        \n",
       "\n",
       "        current_price__permutation_entropy__dimension_6__tau_1  \\\n",
       "464801                                           1.214718        \n",
       "\n",
       "        current_price__permutation_entropy__dimension_7__tau_1  \\\n",
       "464801                                           1.431578        \n",
       "\n",
       "        current_price__query_similarity_count__query_None__threshold_0.0  \\\n",
       "464801                                                0.0                  \n",
       "\n",
       "        current_price__matrix_profile__feature_\"min\"__threshold_0.98  \\\n",
       "464801                                           3.102753              \n",
       "\n",
       "        current_price__matrix_profile__feature_\"max\"__threshold_0.98  \\\n",
       "464801                                           6.447728              \n",
       "\n",
       "        current_price__matrix_profile__feature_\"mean\"__threshold_0.98  \\\n",
       "464801                                            4.95205               \n",
       "\n",
       "        current_price__matrix_profile__feature_\"median\"__threshold_0.98  \\\n",
       "464801                                           5.078272                 \n",
       "\n",
       "        current_price__matrix_profile__feature_\"25\"__threshold_0.98  \\\n",
       "464801                                            4.35793             \n",
       "\n",
       "        current_price__matrix_profile__feature_\"75\"__threshold_0.98  \n",
       "464801                                           5.504583            \n",
       "\n",
       "[1 rows x 2361 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_features_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7caefa-4669-4ae0-92d5-595a57ea7a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feature_selection = select_features(x_df[numeric_columns], y_df['sold_quantity_mean'])\n",
    "set(numeric_columns) - set(x_feature_selection.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c804b9c3-a750-429f-8ac3-0107f3dc1211",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = ['item_domain_id', 'item_id', 'item_title', 'site_id', 'sku',\n",
    "       'product_id', 'product_family_id', 'count', 'date_first', 'date_last',\n",
    "       'date_diff', 'date_first_day', 'date_first_month', 'date_last_day',\n",
    "       'date_last_month', 'sold_quantity_first', 'sold_quantity_last',\n",
    "       'sold_quantity_sum', 'sold_quantity_mean', 'sold_quantity_std',\n",
    "       'sold_quantity_min', 'sold_quantity_max', 'sold_quantity_mode',\n",
    "       'sold_quantity_mode_tx', 'current_price_first', 'current_price_last',\n",
    "       'current_price_sum', 'current_price_mean', 'current_price_std',\n",
    "       'current_price_min', 'current_price_max', 'current_price_mode',\n",
    "       'current_price_mode_tx', 'minutes_active_first', 'minutes_active_last',\n",
    "       'minutes_active_sum', 'minutes_active_mean', 'minutes_active_std',\n",
    "       'minutes_active_min', 'minutes_active_max', 'minutes_active_mode',\n",
    "       'minutes_active_mode_tx', 'currency_first', 'currency_last',\n",
    "       'currency_mode', 'currency_mode_tx', 'listing_type_first',\n",
    "       'listing_type_last', 'listing_type_mode', 'listing_type_mode_tx',\n",
    "       'shipping_logistic_type_first', 'shipping_logistic_type_last',\n",
    "       'shipping_logistic_type_mode', 'shipping_logistic_type_mode_tx',\n",
    "       'shipping_payment_first', 'shipping_payment_last',\n",
    "       'shipping_payment_mode', 'shipping_payment_mode_tx',\n",
    "       'minutes_active_series', 'current_price_series',\n",
    "       'sold_quantity_series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e0345e90-a853-40cc-8445-735dafdf290c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 140 Non-used features:  {'sku', 'date_first', 'date_last', 'item_title', 'date_diff'}\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = ['site_id', 'item_id']\n",
    "categorical_columns_with_nan = ['item_domain_id', 'product_id', 'product_family_id']\n",
    "categorical_columns_composed = ['currency', 'listing_type', 'shipping_logistic_type', 'shipping_payment']\n",
    "categorical_composed_suffix = ['_first', '_last', '_mode']\n",
    "\n",
    "categorical_columns = categorical_columns + categorical_columns_with_nan\n",
    "for category_name in categorical_columns_composed:\n",
    "    for suffix in categorical_composed_suffix:\n",
    "        categorical_columns.append(category_name+suffix)\n",
    "\n",
    "numeric_columns = ['count', 'date_first_day', 'date_first_month', 'date_last_day', 'date_last_month']  \n",
    "numeric_columns_composed = ['sold_quantity', 'current_price', 'minutes_active']\n",
    "numeric_composed_suffix = ['_first', '_last', '_mode', '_mode_tx', '_sum', '_mean', '_std', '_min', '_max']\n",
    "\n",
    "for numeric_name in numeric_columns_composed:\n",
    "    for suffix in numeric_composed_suffix:\n",
    "        numeric_columns.append(numeric_name+suffix)\n",
    "\n",
    "categorical_to_numeric_composed_suffix = ['_mode_tx']\n",
    "        \n",
    "for category_name in categorical_columns_composed:\n",
    "    for suffix in categorical_to_numeric_composed_suffix:\n",
    "        numeric_columns.append(category_name+suffix)\n",
    "        \n",
    "series_columns = ['sold_quantity_series', 'current_price_series', 'minutes_active_series']\n",
    "series_columns_headers = {}\n",
    "\n",
    "series_columns_max = x_df['count'].max()\n",
    "for series_name in series_columns:\n",
    "    series_columns_headers[series_name] = [series_name+'_'+str(i) for i in range(series_columns_max)]\n",
    "    numeric_columns = numeric_columns + series_columns_headers[series_name]\n",
    "\n",
    "features = numeric_columns + categorical_columns\n",
    "\n",
    "print('Number of features:', len(features), 'Non-used features: ', set(all_columns) - set(features) - set(series_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6818f3dd-9677-421e-aa93-ce2cede77828",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in numeric_columns_composed:\n",
    "    x_df[column+'_std'] = x_df[column+'_std'].fillna(0)\n",
    "    y_df[column+'_std'] = y_df[column+'_std'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7c2631b-cb8a-465b-bca9-8406472f7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in categorical_columns_with_nan:    \n",
    "    x_df[column] = x_df[column].astype(str).astype(\"category\")\n",
    "    y_df[column] = y_df[column].astype(str).astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72ddc828-4376-439e-8666-db8c5f3c1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pandas_order = {}\n",
    "\n",
    "for column in categorical_columns:    \n",
    "    x_df[column] = x_df[column].astype(\"category\")\n",
    "    categorical_pandas_order[column] = x_df[column].cat.categories\n",
    "    y_df[column] = y_df[column].astype(\"category\")\n",
    "    y_df[column] = y_df[column].cat.set_categories(categorical_pandas_order[column], ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ec82c6d-2684-4056-b0ac-49a5b0e0a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in categorical_columns:\n",
    "    x_df[column] = x_df[column].cat.codes\n",
    "    y_df[column] = y_df[column].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6efda710-4108-435b-8895-0de31d8fffa2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for column in  series_columns:\n",
    "    def series_to_df(data):\n",
    "        result = np.ones(series_columns_max)*-1\n",
    "        data = json.loads(data)\n",
    "        index_limit = len(data) if len(data) <= series_columns_max else series_columns_max\n",
    "        result[-index_limit:] = data[-index_limit:]\n",
    "        #return result\n",
    "        return pd.Series(result, index=series_columns_headers[column])\n",
    "\n",
    "    series_x_df = x_df[column].parallel_apply(series_to_df)\n",
    "    series_y_df = y_df[column].parallel_apply(series_to_df)\n",
    "\n",
    "    x_df = x_df.join(series_x_df)\n",
    "    y_df = y_df.join(series_y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c9fafd68-eb2a-4a50-b9fc-bb2919a0fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x_df[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e73e3da9-5c86-4679-832f-cb675ef08b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = y_df[['sold_quantity_mean', 'sold_quantity_std']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61b58e32-059b-4439-88e0-c0dd4e5840bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(list(y_df['sold_quantity_series'].apply(json.loads).values))\n",
    "y = y.cumsum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58d8d499-ce04-48ec-8441-1318643815df",
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT_N = 1\n",
    "\n",
    "index_list = []\n",
    "y_ts = []\n",
    "y_td = []\n",
    "\n",
    "for i, t in enumerate(y):\n",
    "    target_stocks, target_dates = np.unique(t, return_index=True)\n",
    "    if target_stocks[0] == 0:\n",
    "        target_stocks = target_stocks[1:]\n",
    "        target_dates = target_dates[1:]\n",
    "    size = len(target_stocks)\n",
    "    index = np.arange(size)\n",
    "    if size > SELECT_N:\n",
    "        np.random.shuffle(index)\n",
    "        index = index[:SELECT_N]\n",
    "    \n",
    "    for target_stock, target_date in zip(target_stocks[index], target_dates[index]):\n",
    "        index_list.append(i)\n",
    "        y_ts.append(target_stock)\n",
    "        y_td.append(target_date)\n",
    "        \n",
    "index_list = np.array(index_list)\n",
    "y_ts = np.array(y_ts)\n",
    "y_td = np.array(y_td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8a50e86-e2db-4462-a0be-63fb5c319fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1237446"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ccaac1e9-f20a-4df7-8f4f-035877571636",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[index_list]\n",
    "X = np.concatenate((X, np.reshape(y_ts, (-1, 1))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3414ecf-abb8-42a4-a5c5-00a55df6ae20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1690078d-85b4-42da-860a-3105a6fd4ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]),\n",
       " array([50442, 48117, 45274, 41893, 39224, 37287, 41841, 43899, 43436,\n",
       "        41162, 38633, 34867, 34733, 40971, 42642, 41596, 40853, 37383,\n",
       "        34507, 34600, 41461, 43038, 43143, 42910, 40104, 36753, 36775,\n",
       "        45297, 47599, 47006]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "78030a57-e0e8-4f76-8f7d-5d7ece22ac60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "60e773d4-3cc8-479c-991d-7d84bd7bef37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'count',\n",
       " 'currency_mode_tx',\n",
       " 'date_first_day',\n",
       " 'date_last_day',\n",
       " 'date_last_month',\n",
       " 'shipping_payment_mode_tx'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fcee92c-fb54-4fe0-8cf9-4f4194c2b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_df = df_test_fromtrain_x_features.set_index('sku').loc[df_test['sku']].reset_index().copy()\n",
    "for column in numeric_columns_composed:\n",
    "    test_x_df[column+'_std'] = test_x_df[column+'_std'].fillna(0)\n",
    "for column in categorical_columns_with_nan:    \n",
    "    test_x_df[column] = test_x_df[column].astype(str).astype(\"category\")\n",
    "for column in categorical_columns:\n",
    "    test_x_df[column] = test_x_df[column].astype(\"category\")\n",
    "    categorical_order = list(categorical_pandas_order[column])\n",
    "    if len(test_x_df[column].cat.categories) != len(categorical_pandas_order[column]):\n",
    "        for cat in set(test_x_df[column].cat.categories) - set(categorical_order):\n",
    "                categorical_order.append(cat)\n",
    "    test_x_df[column] = test_x_df[column].cat.set_categories(categorical_order, ordered=True)\n",
    "    test_x_df[column] = test_x_df[column].cat.codes\n",
    "for column in  series_columns:\n",
    "    def series_to_df(data):\n",
    "        result = np.ones(series_columns_max)*-1\n",
    "        data = json.loads(data)\n",
    "        index_limit = len(data) if len(data) <= series_columns_max else series_columns_max\n",
    "        result[-index_limit:] = data[-index_limit:]\n",
    "        #return result\n",
    "        return pd.Series(result, index=series_columns_headers[column])\n",
    "\n",
    "    series_x_test_df = test_x_df[column].parallel_apply(series_to_df)\n",
    "\n",
    "    test_x_df = test_x_df.join(series_x_test_df)\n",
    "\n",
    "X_test = test_x_df[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b797bfc7-1d2c-4ec2-b9f3-d13c6329dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.concatenate((X_test, np.reshape(df_test['target_stock'].values, (-1, 1))), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6c832bb-ba9e-44d1-9ba4-75d11b366937",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267f1c41-7bde-4324-8df5-5e0fafe0a395",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/edugarcia/dependencies/xgboost/python-package/xgboost/sklearn.py:1204: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:01:06] WARNING: /home/edugarcia/dependencies/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-32-8ddfd8425afc>\", line 9, in <module>\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"/home/edugarcia/dependencies/xgboost/python-package/xgboost/core.py\", line 498, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/edugarcia/dependencies/xgboost/python-package/xgboost/sklearn.py\", line 1241, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"/home/edugarcia/dependencies/xgboost/python-package/xgboost/training.py\", line 196, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"/home/edugarcia/dependencies/xgboost/python-package/xgboost/training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/edugarcia/dependencies/xgboost/python-package/xgboost/core.py\", line 1669, in update\n",
      "    dtrain.handle))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-32-8ddfd8425afc>\", line 9, in <module>\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"/home/edugarcia/dependencies/xgboost/python-package/xgboost/core.py\", line 498, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/edugarcia/dependencies/xgboost/python-package/xgboost/sklearn.py\", line 1241, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"/home/edugarcia/dependencies/xgboost/python-package/xgboost/training.py\", line 196, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"/home/edugarcia/dependencies/xgboost/python-package/xgboost/training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/edugarcia/dependencies/xgboost/python-package/xgboost/core.py\", line 1669, in update\n",
      "    dtrain.handle))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/posixpath.py\", line 416, in _joinrealpath\n",
      "    if not name or name == curdir:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-32-8ddfd8425afc>\", line 9, in <module>\n",
      "    model.fit(X_train, y_train)\n",
      "  File \"/home/edugarcia/dependencies/xgboost/python-package/xgboost/core.py\", line 498, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/home/edugarcia/dependencies/xgboost/python-package/xgboost/sklearn.py\", line 1241, in fit\n",
      "    callbacks=callbacks,\n",
      "  File \"/home/edugarcia/dependencies/xgboost/python-package/xgboost/training.py\", line 196, in train\n",
      "    early_stopping_rounds=early_stopping_rounds)\n",
      "  File \"/home/edugarcia/dependencies/xgboost/python-package/xgboost/training.py\", line 81, in _train_internal\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/edugarcia/dependencies/xgboost/python-package/xgboost/core.py\", line 1669, in update\n",
      "    dtrain.handle))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3263, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3360, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1193, in structured_traceback\n",
      "    tb_offset)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2895, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3072, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3282, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2047, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1436, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1336, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1211, in structured_traceback\n",
      "    chained_exceptions_tb_offset)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1150, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 451, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/opt/conda/envs/torch/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "#model = MultiOutputRegressor(XGBRegressor(\n",
    "#                         n_estimators=800, max_depth=2, learning_rate=0.01,\n",
    "#                         random_state=0, tree_method='gpu_hist',\n",
    "#                         gpu_id=3), n_jobs=14)\n",
    "model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, reg_lambda=5e-1,\n",
    "                    random_state=0, tree_method='gpu_hist', objective='multi:softprob', num_class=30,\n",
    "                    gpu_id=3)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict_proba(X_val)\n",
    "y_pred = (y_pred/y_pred.sum(axis=1)[:,None]).round(4)\n",
    "rps(y_pred, np.eye(30)[y_val.astype(int)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0104dd6e-e475-416e-9e88-fc720771ef0c",
   "metadata": {},
   "source": [
    "n_estimators=1000, max_depth=2, learning_rate=0.08, 38.77598546656583\n",
    "model = XGBRegressor(n_estimators=1000, max_depth=2, learning_rate=0.2, 38.27539167059256\n",
    "n_estimators=1000, max_depth=4, learning_rate=0.1, 37.546678641103945\n",
    "n_estimators=1000, max_depth=6, learning_rate=0.1, 37.40878445231095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4086198b-7734-46c6-9a99-991e90460da0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 170\n",
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "params [259, 0.0031266912307463765, 8, 0.5871651421518383, 0.4512494775682321, 31]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-95c1570a355c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m          \u001b[0;34m(\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m          (1,300)]\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtune\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macq_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"lbfgs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         callback=callback, n_jobs=n_jobs, model_queue_size=model_queue_size)\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, n_initial_points, initial_point_generator, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-95c1570a355c>\u001b[0m in \u001b[0;36mtune\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     10\u001b[0m                        \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'multi:softprob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                        tree_method='gpu_hist', gpu_id=3)\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dependencies/xgboost/python-package/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dependencies/xgboost/python-package/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1225\u001b[0m             \u001b[0mcreate_dmatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m             \u001b[0menable_categorical\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_categorical\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1227\u001b[0;31m             \u001b[0mlabel_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1228\u001b[0m         )\n\u001b[1;32m   1229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dependencies/xgboost/python-package/xgboost/sklearn.py\u001b[0m in \u001b[0;36m_wrap_evaluation_matrices\u001b[0;34m(missing, X, y, group, qid, sample_weight, base_margin, feature_weights, eval_set, sample_weight_eval_set, base_margin_eval_set, eval_group, eval_qid, create_dmatrix, enable_categorical, label_transform)\u001b[0m\n\u001b[1;32m    279\u001b[0m     train_dmatrix = create_dmatrix(\n\u001b[1;32m    280\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabel_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m         \u001b[0mgroup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mqid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/sklearn/preprocessing/_label.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/sklearn/utils/_encode.py\u001b[0m in \u001b[0;36m_encode\u001b[0;34m(values, uniques, check_unknown)\u001b[0m\n\u001b[1;32m    185\u001b[0m                 raise ValueError(f\"y contains previously unseen labels: \"\n\u001b[1;32m    186\u001b[0m                                  f\"{str(diff)}\")\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msearchsorted\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msearchsorted\u001b[0;34m(a, v, side, sorter)\u001b[0m\n\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \"\"\"\n\u001b[0;32m-> 1343\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'searchsorted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mside\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/torch/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "\n",
    "def tune(params):\n",
    "    print('params', params)\n",
    "    model = XGBClassifier(n_estimators=params[0], learning_rate=params[1],\n",
    "                       max_depth=params[2],\n",
    "                       subsample=params[3],\n",
    "                       colsample_bytree=params[4],\n",
    "                       min_child_weight=params[5],\n",
    "                       random_state=42, objective='multi:softprob', num_class=30,\n",
    "                       tree_method='gpu_hist', gpu_id=3)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict_proba(X_val)\n",
    "    y_pred = (y_pred/y_pred.sum(axis=1)[:,None]).round(4)\n",
    "    return rps(y_pred, np.eye(30)[y_val.astype(int)])\n",
    "\n",
    "space = [(100, 300),\n",
    "         (1e-3, 5e-1, 'log-uniform'),\n",
    "         (1, 10),\n",
    "         (0.05, 0.95),\n",
    "         (0.05, 0.95),\n",
    "         (1,300)]\n",
    "res = gp_minimize(tune, space, random_state=42, verbose=1, acq_optimizer=\"lbfgs\", n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e79527-93d6-407c-9f61-4b148e0359fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "#features_importances = model.estimators_[-1].feature_importances_\n",
    "features_importances = model.feature_importances_\n",
    "sort = np.flip(np.argsort(features_importances))[0:30]\n",
    "ax.barh(np.array(features + ['target_stock'])[sort], features_importances[sort])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7410cec-ce87-4567-85f4-da3d3997d00e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "variables_to_train = np.flip(np.argsort(features_importances))[0:15]\n",
    "model = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.2,\n",
    "                    random_state=0, tree_method='gpu_hist', objective='multi:softprob', num_class=30,\n",
    "                    gpu_id=3)\n",
    "model.fit(X, y)\n",
    "preds = model.predict_proba(X_test)\n",
    "preds = (preds/preds.sum(axis=1)[:,None]).round(4)\n",
    "rps(preds, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141529d6-9373-405e-8d02-7a8b6635f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(n_estimators=1000, max_depth=6, learning_rate=0.1,\n",
    "                    random_state=0, tree_method='gpu_hist', objective='multi:softprob', num_class=30,\n",
    "                    gpu_id=3)\n",
    "model.fit(X, y)\n",
    "preds = model.predict_proba(X_test)\n",
    "preds = (preds/preds.sum(axis=1)[:,None]).round(4)\n",
    "rps(preds, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e66882-c790-4d29-8186-98829bc1fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(arr, num, fill_value=0):\n",
    "    result = np.empty_like(arr)\n",
    "    if num > 0:\n",
    "        result[:num] = fill_value\n",
    "        result[num:] = arr[:-num]\n",
    "    elif num < 0:\n",
    "        result[num:] = fill_value\n",
    "        result[:num] = arr[-num:]\n",
    "    else:\n",
    "        result[:] = arr\n",
    "    return result\n",
    "\n",
    "def gaussian_kernel1d(sigma, length, order=0):\n",
    "    \"\"\"\n",
    "    Computes a 1-D Gaussian convolution kernel.\n",
    "    \"\"\"\n",
    "    if order < 0:\n",
    "        raise ValueError('order must be non-negative')\n",
    "    exponent_range = np.arange(order + 1)\n",
    "    sigma2 = sigma * sigma\n",
    "    x = np.arange(np.floor(-length/2), np.ceil(length/2))\n",
    "    phi_x = np.exp(-0.5 / sigma2 * x ** 2)\n",
    "    phi_x = phi_x / phi_x.sum()\n",
    "    return phi_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14538490-e73f-4906-9dd8-a44f8c2bfefa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "probabilities = np.zeros((len(df_test), 30))\n",
    "\n",
    "normalized_preds = (preds.round()+0.5).astype(int)\n",
    "for i in np.arange(2, 8, 0.1):\n",
    "    gaussian_len = 30\n",
    "    sigma = i\n",
    "    #sigma = sigma if sigma > 0 else 1\n",
    "    gaussian = gaussian_kernel1d(sigma, gaussian_len)\n",
    "    gassian_possibilites = np.zeros((30, 30))\n",
    "    gaussian_central_point = 15\n",
    "    for j in range(30):\n",
    "        target_day = j\n",
    "        shift_amount = target_day-gaussian_central_point\n",
    "        probs = shift(gaussian, shift_amount)\n",
    "        probs = probs/probs.sum()\n",
    "        gassian_possibilites[j] = probs.round(4)\n",
    "    \n",
    "    probabilities = gassian_possibilites[normalized_preds]\n",
    "\n",
    "    print(sigma, rps(probabilities, ground_truth))\n",
    "\n",
    "#\n",
    "#Melhor sigma == 7.1 rps- 4.156727036526029\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be034cb-cba3-4327-9c0e-7c6160e242f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8328f3c5-de4b-4019-b8f3-33bc4567cdc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.5 + 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d32a40e-075d-4ea6-b160-da96c6fbdb8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = np.zeros((len(df_test), 30))\n",
    "\n",
    "#normalized_preds = (preds.round() + 1).astype(int)\n",
    "\n",
    "gaussian_len = 30\n",
    "gaussian_central_point = 15\n",
    "sigma = 7.1\n",
    "\n",
    "for j, pred in enumerate(preds):\n",
    "    target_day = pred.round().astype(int)\n",
    "    target_day = np.clip(target_day, 0, 29)\n",
    "    #sigma = sigma if sigma > 0 else 1\n",
    "    #sigma = np.abs(0.5 -(np.abs(target_day - pred))/0.5)*14\n",
    "    gaussian = gaussian_kernel1d(sigma, gaussian_len)\n",
    "    shift_amount = target_day-gaussian_central_point\n",
    "    probs = shift(gaussian, shift_amount)\n",
    "    probs[target_day+1:] = 0\n",
    "    probs = probs/probs.sum()\n",
    "    probabilities[j] = probs.round(4)\n",
    "\n",
    "print(sigma, rps(probabilities, ground_truth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8906d692-1caf-4771-8097-b300b4697a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544d18d6-8b93-4a66-a376-58dac75d95c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06b78b8-fe44-4979-b9df-cb9279fe5dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc0b36e-a2b9-4de7-88eb-2219c8b1ddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def normal_probs(data):\n",
    "    row, pred = data\n",
    "    sku = row['sku']\n",
    "    target_stock = row['target_stock']\n",
    "    \n",
    "    #sold_mean, sold_std = pred\n",
    "    \n",
    "    \n",
    "    days_stockout = pred+1\n",
    "    std_days = 7\n",
    "\n",
    "    dist_model = norm(days_stockout,std_days)\n",
    "\n",
    "    probalities = np.zeros(30)\n",
    "    for i in range(1, 31):\n",
    "        probalities[i-1] = (dist_model.cdf(i+1) - dist_model.cdf(i))\n",
    "\n",
    "    if probalities.sum() == 0:\n",
    "        probalities = np.ones(30) / 30\n",
    "\n",
    "    probalities = (probalities/probalities.sum()).round(4)\n",
    "    #probalities = saferound(probalities, places=4)\n",
    "    return (sku, probalities)\n",
    "\n",
    "predictions = np.zeros((len(df_test), 30))\n",
    "i = 0\n",
    "with Pool(100) as p:\n",
    "    for data in tqdm(p.imap(normal_probs, zip(df_test.to_dict(orient='records'), preds)), total=len(df_test)):\n",
    "        sku, probabilities = data\n",
    "        predictions[i] = probabilities\n",
    "        i += 1\n",
    "        \n",
    "from evaluate import rps\n",
    "rps(predictions, ground_truth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9876218e-a1a5-4727-9e01-2aac7259e335",
   "metadata": {},
   "source": [
    "stds\n",
    "5 - 4.262929225335388\n",
    "7 - 4.198544959223248\n",
    "10 - 4.3...\n",
    "8 - 4.22\n",
    "6 - 4.204762802167254"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77db7399-04ff-438b-a321-dd7d4e46ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import rps\n",
    "rps(predictions, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d42d08c-857e-4fc3-9188-cdb7fedc84c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def normal_probs(data):\n",
    "    row, preds = data\n",
    "    sku = row['sku']\n",
    "    target_stock = row['target_stock']\n",
    "    \n",
    "    sold_mean = preds.mean()\n",
    "    sold_std = preds.std()\n",
    "    \n",
    "    c = preds.cumsum()  \n",
    "    days_stockout = np.where(c>target_stock)[0]\n",
    "    days_stockout = 30 if len(days_stockout) == 0 else days_stockout[0]+1\n",
    "    \n",
    "    std_days = (sold_std / sold_mean) * days_stockout\n",
    "\n",
    "    dist_model = norm(days_stockout,std_days)\n",
    "\n",
    "    probalities = np.zeros(30)\n",
    "    for i in range(1, 31):\n",
    "        probalities[i-1] = (dist_model.cdf(i+1) - dist_model.cdf(i))\n",
    "\n",
    "    if probalities.sum() == 0:\n",
    "        probalities = np.ones(30) / 30\n",
    "\n",
    "    probalities = (probalities/probalities.sum()).round(4)\n",
    "    #probalities = saferound(probalities, places=4)\n",
    "    return (sku, probalities)\n",
    "\n",
    "predictions = np.zeros((len(df_test), 30))\n",
    "i = 0\n",
    "with Pool(50) as p:\n",
    "    for data in tqdm(p.imap(normal_probs, zip(df_test.to_dict(orient='records'), y_pred)), total=len(df_test)):\n",
    "        sku, probabilities = data\n",
    "        predictions[i] = probabilities\n",
    "        i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
